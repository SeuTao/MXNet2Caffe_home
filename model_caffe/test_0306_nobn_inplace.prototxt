name: "mxnet-mdoel"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape: { dim: 1 dim: 1 dim: 128 dim: 128 }
  }
}

layer {
  bottom: "data"
  top: "bn_data"
  name: "bn_data"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "bn_data"
	top: "conv0"
	name: "conv0"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 7
		pad: 3
		stride: 2
		bias_term: true
	}
}

layer {
  bottom: "conv0"
  top: "conv0"
  name: "activation0"
  type: "ReLU"
}

layer {
  bottom: "conv0"
  top: "pooling0"
  name: "pooling0"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}

layer {
	bottom: "pooling0"
	top: "first_unit_conv1"
	name: "first_unit_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "first_unit_conv1"
  top: "first_unit_conv1"
  name: "activation1"
  type: "ReLU"
}

layer {
	bottom: "first_unit_conv1"
	top: "first_unit_conv2"
	name: "first_unit_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "first_unit_conv2"
  top: "first_unit_conv2"
  name: "activation2"
  type: "ReLU"
}

layer {
	bottom: "first_unit_conv2"
	top: "first_unit_conv3"
	name: "first_unit_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "first_unit_conv1"
	top: "first_unit_sc"
	name: "first_unit_sc"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus0"
  type: "Eltwise"
  bottom: "first_unit_conv3"
  bottom: "first_unit_sc"
  top: "_plus0"
}

layer {
  bottom: "_plus0"
  top: "stage1_unit2_bn1"
  name: "stage1_unit2_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_unit2_bn1"
  top: "stage1_unit2_bn1"
  name: "activation3"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit2_bn1"
	top: "stage1_unit2_conv1"
	name: "stage1_unit2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  name: "activation4"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit2_conv1"
	top: "stage1_unit2_conv2"
	name: "stage1_unit2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  name: "activation5"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit2_conv2"
	top: "stage1_unit2_conv3"
	name: "stage1_unit2_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus1"
  type: "Eltwise"
  bottom: "stage1_unit2_conv3"
  bottom: "_plus0"
  top: "_plus1"
}

layer {
  bottom: "_plus1"
  top: "stage1_unit3_bn1"
  name: "stage1_unit3_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_unit3_bn1"
  top: "stage1_unit3_bn1"
  name: "activation6"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit3_bn1"
	top: "stage1_unit3_conv1"
	name: "stage1_unit3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  name: "activation7"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit3_conv1"
	top: "stage1_unit3_conv2"
	name: "stage1_unit3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 32
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  name: "activation8"
  type: "ReLU"
}

layer {
	bottom: "stage1_unit3_conv2"
	top: "stage1_unit3_conv3"
	name: "stage1_unit3_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus2"
  type: "Eltwise"
  bottom: "stage1_unit3_conv3"
  bottom: "_plus1"
  top: "_plus2"
}

layer {
  bottom: "_plus2"
  top: "stage2_unit1_bn1"
  name: "stage2_unit1_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_unit1_bn1"
  top: "stage2_unit1_bn1"
  name: "activation9"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit1_bn1"
	top: "stage2_unit1_conv1"
	name: "stage2_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  name: "activation10"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit1_conv1"
	top: "stage2_unit1_conv2"
	name: "stage2_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  name: "activation11"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit1_conv2"
	top: "stage2_unit1_conv3"
	name: "stage2_unit1_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "stage2_unit1_bn1"
	top: "stage2_unit1_sc"
	name: "stage2_unit1_sc"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  name: "_plus3"
  type: "Eltwise"
  bottom: "stage2_unit1_conv3"
  bottom: "stage2_unit1_sc"
  top: "_plus3"
}

layer {
  bottom: "_plus3"
  top: "stage2_unit2_bn1"
  name: "stage2_unit2_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_unit2_bn1"
  top: "stage2_unit2_bn1"
  name: "activation12"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit2_bn1"
	top: "stage2_unit2_conv1"
	name: "stage2_unit2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  name: "activation13"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit2_conv1"
	top: "stage2_unit2_conv2"
	name: "stage2_unit2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  name: "activation14"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit2_conv2"
	top: "stage2_unit2_conv3"
	name: "stage2_unit2_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus4"
  type: "Eltwise"
  bottom: "stage2_unit2_conv3"
  bottom: "_plus3"
  top: "_plus4"
}

layer {
  bottom: "_plus4"
  top: "stage2_unit3_bn1"
  name: "stage2_unit3_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_unit3_bn1"
  top: "stage2_unit3_bn1"
  name: "activation15"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit3_bn1"
	top: "stage2_unit3_conv1"
	name: "stage2_unit3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  name: "activation16"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit3_conv1"
	top: "stage2_unit3_conv2"
	name: "stage2_unit3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  name: "activation17"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit3_conv2"
	top: "stage2_unit3_conv3"
	name: "stage2_unit3_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus5"
  type: "Eltwise"
  bottom: "stage2_unit3_conv3"
  bottom: "_plus4"
  top: "_plus5"
}

layer {
  bottom: "_plus5"
  top: "stage2_unit4_bn1"
  name: "stage2_unit4_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_unit4_bn1"
  top: "stage2_unit4_bn1"
  name: "activation18"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit4_bn1"
	top: "stage2_unit4_conv1"
	name: "stage2_unit4_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  name: "activation19"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit4_conv1"
	top: "stage2_unit4_conv2"
	name: "stage2_unit4_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  name: "activation20"
  type: "ReLU"
}

layer {
	bottom: "stage2_unit4_conv2"
	top: "stage2_unit4_conv3"
	name: "stage2_unit4_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus6"
  type: "Eltwise"
  bottom: "stage2_unit4_conv3"
  bottom: "_plus5"
  top: "_plus6"
}

layer {
  bottom: "_plus6"
  top: "stage3_unit1_bn1"
  name: "stage3_unit1_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit1_bn1"
  top: "stage3_unit1_bn1"
  name: "activation21"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit1_bn1"
	top: "stage3_unit1_conv1"
	name: "stage3_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  name: "activation22"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit1_conv1"
	top: "stage3_unit1_conv2"
	name: "stage3_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  name: "activation23"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit1_conv2"
	top: "stage3_unit1_conv3"
	name: "stage3_unit1_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "stage3_unit1_bn1"
	top: "stage3_unit1_sc"
	name: "stage3_unit1_sc"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  name: "_plus7"
  type: "Eltwise"
  bottom: "stage3_unit1_conv3"
  bottom: "stage3_unit1_sc"
  top: "_plus7"
}

layer {
  bottom: "_plus7"
  top: "stage3_unit2_bn1"
  name: "stage3_unit2_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit2_bn1"
  top: "stage3_unit2_bn1"
  name: "activation24"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit2_bn1"
	top: "stage3_unit2_conv1"
	name: "stage3_unit2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  name: "activation25"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit2_conv1"
	top: "stage3_unit2_conv2"
	name: "stage3_unit2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  name: "activation26"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit2_conv2"
	top: "stage3_unit2_conv3"
	name: "stage3_unit2_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus8"
  type: "Eltwise"
  bottom: "stage3_unit2_conv3"
  bottom: "_plus7"
  top: "_plus8"
}

layer {
  bottom: "_plus8"
  top: "stage3_unit3_bn1"
  name: "stage3_unit3_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit3_bn1"
  top: "stage3_unit3_bn1"
  name: "activation27"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit3_bn1"
	top: "stage3_unit3_conv1"
	name: "stage3_unit3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  name: "activation28"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit3_conv1"
	top: "stage3_unit3_conv2"
	name: "stage3_unit3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  name: "activation29"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit3_conv2"
	top: "stage3_unit3_conv3"
	name: "stage3_unit3_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus9"
  type: "Eltwise"
  bottom: "stage3_unit3_conv3"
  bottom: "_plus8"
  top: "_plus9"
}

layer {
  bottom: "_plus9"
  top: "stage3_unit4_bn1"
  name: "stage3_unit4_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit4_bn1"
  top: "stage3_unit4_bn1"
  name: "activation30"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit4_bn1"
	top: "stage3_unit4_conv1"
	name: "stage3_unit4_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  name: "activation31"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit4_conv1"
	top: "stage3_unit4_conv2"
	name: "stage3_unit4_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  name: "activation32"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit4_conv2"
	top: "stage3_unit4_conv3"
	name: "stage3_unit4_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus10"
  type: "Eltwise"
  bottom: "stage3_unit4_conv3"
  bottom: "_plus9"
  top: "_plus10"
}

layer {
  bottom: "_plus10"
  top: "stage3_unit5_bn1"
  name: "stage3_unit5_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit5_bn1"
  top: "stage3_unit5_bn1"
  name: "activation33"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit5_bn1"
	top: "stage3_unit5_conv1"
	name: "stage3_unit5_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  name: "activation34"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit5_conv1"
	top: "stage3_unit5_conv2"
	name: "stage3_unit5_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  name: "activation35"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit5_conv2"
	top: "stage3_unit5_conv3"
	name: "stage3_unit5_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus11"
  type: "Eltwise"
  bottom: "stage3_unit5_conv3"
  bottom: "_plus10"
  top: "_plus11"
}

layer {
  bottom: "_plus11"
  top: "stage3_unit6_bn1"
  name: "stage3_unit6_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit6_bn1"
  top: "stage3_unit6_bn1"
  name: "activation36"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit6_bn1"
	top: "stage3_unit6_conv1"
	name: "stage3_unit6_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  name: "activation37"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit6_conv1"
	top: "stage3_unit6_conv2"
	name: "stage3_unit6_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  name: "activation38"
  type: "ReLU"
}

layer {
	bottom: "stage3_unit6_conv2"
	top: "stage3_unit6_conv3"
	name: "stage3_unit6_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus12"
  type: "Eltwise"
  bottom: "stage3_unit6_conv3"
  bottom: "_plus11"
  top: "_plus12"
}

layer {
  bottom: "_plus12"
  top: "stage4_unit1_bn1"
  name: "stage4_unit1_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_unit1_bn1"
  top: "stage4_unit1_bn1"
  name: "activation39"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit1_bn1"
	top: "stage4_unit1_conv1"
	name: "stage4_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  name: "activation40"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit1_conv1"
	top: "stage4_unit1_conv2"
	name: "stage4_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  name: "activation41"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit1_conv2"
	top: "stage4_unit1_conv3"
	name: "stage4_unit1_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
	bottom: "stage4_unit1_bn1"
	top: "stage4_unit1_sc"
	name: "stage4_unit1_sc"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  name: "_plus13"
  type: "Eltwise"
  bottom: "stage4_unit1_conv3"
  bottom: "stage4_unit1_sc"
  top: "_plus13"
}

layer {
  bottom: "_plus13"
  top: "stage4_unit2_bn1"
  name: "stage4_unit2_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_unit2_bn1"
  top: "stage4_unit2_bn1"
  name: "activation42"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit2_bn1"
	top: "stage4_unit2_conv1"
	name: "stage4_unit2_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  name: "activation43"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit2_conv1"
	top: "stage4_unit2_conv2"
	name: "stage4_unit2_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  name: "activation44"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit2_conv2"
	top: "stage4_unit2_conv3"
	name: "stage4_unit2_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus14"
  type: "Eltwise"
  bottom: "stage4_unit2_conv3"
  bottom: "_plus13"
  top: "_plus14"
}

layer {
  bottom: "_plus14"
  top: "stage4_unit3_bn1"
  name: "stage4_unit3_bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_unit3_bn1"
  top: "stage4_unit3_bn1"
  name: "activation45"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit3_bn1"
	top: "stage4_unit3_conv1"
	name: "stage4_unit3_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  name: "activation46"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit3_conv1"
	top: "stage4_unit3_conv2"
	name: "stage4_unit3_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: true
	}
}

layer {
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  name: "activation47"
  type: "ReLU"
}

layer {
	bottom: "stage4_unit3_conv2"
	top: "stage4_unit3_conv3"
	name: "stage4_unit3_conv3"
	type: "Convolution"
	convolution_param {
		num_output: 1024
		kernel_size: 1
		pad: 0
		stride: 1
		bias_term: false
	}
}

layer {
  name: "_plus15"
  type: "Eltwise"
  bottom: "stage4_unit3_conv3"
  bottom: "_plus14"
  top: "_plus15"
}

layer {
  bottom: "_plus15"
  top: "bn1"
  name: "bn1"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "bn1"
  top: "pre_fc1"
  name: "pre_fc1"
  type: "InnerProduct"
  inner_product_param {
    num_output: 512
  }
}

